import streamlit as st
from streamlit_mic_recorder import speech_to_text
import time

# def record_voice(language):
#     """
#     Fixed version: No more 'previous result' issue
#     - Uses session_state + st.rerun() like the original sr version
#     - Single button (mic)
#     - Auto-recognize on stop
#     """
#     # Language mapping
#     language_mapping = {
#         "yue_hk": "yue-HK",
#         "zh": "zh-TW",
#         "zh-cn": "zh-CN",
#         "en": "en-US"
#     }
#     google_language = language_mapping.get(language, "yue-HK")

#     # Initialize session state
#     if "is_recording" not in st.session_state:
#         st.session_state["is_recording"] = False
#     if "recorded_text" not in st.session_state:
#         st.session_state["recorded_text"] = ""
#     if "voice_transcribed_text" not in st.session_state:
#         st.session_state["voice_transcribed_text"] = ""

#     # Status placeholder
#     status_placeholder = st.empty()

#     # Show recording status
#     if st.session_state["is_recording"]:
#         status_placeholder.markdown("""
#         <div style="background-color: #e7f3ff; border: 1px solid #2196F3; border-radius: 4px; padding: 10px; margin: 10px 0 -10px -160px; text-align: left;">
#             ğŸ¤ è«‹èªªè©± (æŒ‰ â¹ï¸ åœæ­¢)
#         </div>
#         """, unsafe_allow_html=True)

#     # Single mic button using streamlit_mic_recorder
#     text = speech_to_text(
#         start_prompt="ğŸ¤",
#         stop_prompt="â¹ï¸",
#         language=google_language,
#         use_container_width=True,
#         just_once=True,
#         key="voice_recorder"
#     )

#     # Handle recognition result
#     if text is not None:
#         st.session_state["is_recording"] = False
#         recognized_text = text.strip()

#         # Clear status
#         status_placeholder.empty()

#         if recognized_text:
#             # âœ… æ›´æ–°å…¨å±€çŠ¶æ€
#             st.session_state["recorded_text"] = recognized_text
#             st.session_state["voice_transcribed_text"] = recognized_text
#             st.session_state["input_counter"] = st.session_state.get("input_counter", 0) + 1

#             # âœ… æ˜¾ç¤ºæˆåŠŸ
#             status_placeholder.markdown(f"""
#             <div style="background-color: #e8f5e8; border: 1px solid #4caf50; border-radius: 4px; padding: 10px; margin: 10px 0 -10px -160px; text-align: left;">
#                 âœ… èªéŸ³è­˜åˆ¥å®Œæˆ: {recognized_text}
#             </div>
#             """, unsafe_allow_html=True)

#             time.sleep(1.5)
#             status_placeholder.empty()

#             # âœ… å…³é”®ï¼šè§¦å‘é‡è¿è¡Œï¼Œè®©å¤–éƒ¨è¯»å–æœ€æ–°å€¼
#             st.rerun()

#         else:
#             status_placeholder.markdown("""
#             <div style="background-color: #ffebee; border: 1px solid #f44336; border-radius: 4px; padding: 10px; margin: 10px 0 -10px -160px; text-align: left;">
#                 âŒ æ²’æœ‰è­˜åˆ¥åˆ°èªéŸ³
#             </div>
#             """, unsafe_allow_html=True)
#             time.sleep(1.5)
#             status_placeholder.empty()

#     # Sync recording state from recorder
#     st.session_state["is_recording"] = bool(st.session_state.get("voice_recorder", False))

#     return None  # â—ä¸è¿”å›ç»“æœï¼Œé  session_state å’Œ rerun åŒæ­¥
def record_voice(language):
    # """
    # è¯­éŸ³è¾“å…¥ç»„ä»¶ï¼ˆéº¦å…‹é£æŒ‰é’®ï¼‰
    # - ä½¿ç”¨ streamlit_mic_recorder å®ç°è¯­éŸ³è¯†åˆ«
    # - æç¤ºä¿¡æ¯æ˜¾ç¤ºåœ¨æŒ‰é’®ä¸‹æ–¹ï¼Œé¿å…ç•Œé¢è·³åŠ¨
    # - è¯†åˆ«å®Œæˆåè‡ªåŠ¨æ›´æ–° st.session_state å¹¶åˆ·æ–°é¡µé¢
    # - å¤–éƒ¨åº”é€šè¿‡ st.session_state['voice_transcribed_text'] è·å–è¯†åˆ«ç»“æœ

    # Args:
    #     language (str): è¯­è¨€ä»£ç ï¼Œæ”¯æŒ "yue_hk", "zh", "zh-cn", "en"
    # """
    # # è¯­è¨€æ˜ å°„
    # language_mapping = {
    #     "yue_hk": "yue-HK",  # ç²¤è¯­ï¼ˆé¦™æ¸¯ï¼‰
    #     "zh": "zh-TW",       # ä¸­æ–‡ï¼ˆç¹ä½“ï¼‰
    #     "zh-cn": "zh-CN",    # ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰
    #     "en": "en-US"        # è‹±è¯­
    # }
    # google_language = language_mapping.get(language, "yue-HK")

    # # åˆå§‹åŒ– session_state
    # if "is_recording" not in st.session_state:
    #     st.session_state["is_recording"] = False
    # if "voice_transcribed_text" not in st.session_state:
    #     st.session_state["voice_transcribed_text"] = ""
    # if "input_counter" not in st.session_state:
    #     st.session_state["input_counter"] = 0

    # # ===== ç¬¬ä¸€æ­¥ï¼šæ¸²æŸ“è¯­éŸ³è¯†åˆ«æŒ‰é’® =====
    # text = speech_to_text(
    #     start_prompt="ğŸ¤ è¯­éŸ³è¾“å…¥",
    #     stop_prompt="â¹ï¸ åœæ­¢å½•éŸ³",
    #     language=google_language,
    #     use_container_width=True,
    #     just_once=True,  # æ¯æ¬¡åªè¯†åˆ«ä¸€æ¬¡
    #     key="voice_recorder"  # å¿…é¡»æœ‰ key æ‰èƒ½è®°å½•çŠ¶æ€
    # )

    # # åŒæ­¥ recording çŠ¶æ€ï¼ˆç”¨äº UI åé¦ˆï¼‰
    # st.session_state["is_recording"] = bool(st.session_state.get("voice_recorder", False))

    # # ===== ç¬¬äºŒæ­¥ï¼šåœ¨æŒ‰é’®ä¸‹æ–¹æ˜¾ç¤ºçŠ¶æ€æç¤ºï¼ˆå…³é”®ï¼šé¿å…æŒ‰é’®è·³åŠ¨ï¼‰=====
    # status_placeholder = st.empty()  # å ä½ç¬¦æ”¾åœ¨æŒ‰é’®ä¹‹å

    # if text is not None:
    #     # åœæ­¢å½•éŸ³
    #     st.session_state["is_recording"] = False
    #     recognized_text = text.strip()

    #     # æ¸…é™¤æ—§æç¤º
    #     status_placeholder.empty()

    #     if recognized_text:
    #         # âœ… æˆåŠŸè¯†åˆ«
    #         st.session_state["voice_transcribed_text"] = recognized_text
    #         st.session_state["input_counter"] += 1

    #         status_placeholder.markdown(f"""
    #         <div style="
    #             background-color: #e8f5e8;
    #             border: 1px solid #4caf50;
    #             border-radius: 4px;
    #             padding: 10px;
    #             margin: 10px 0;  /* ä¸Šä¸‹ç•™ç™½ä¸€è‡´ */
    #             font-size: 14px;
    #         ">
    #             âœ… èªéŸ³è­˜åˆ¥å®Œæˆ: <strong>{recognized_text}</strong>
    #         </div>
    #         """, unsafe_allow_html=True)

    #         # ç­‰å¾…ç”¨æˆ·çœ‹åˆ°ç»“æœ
    #         time.sleep(1.2)
    #         status_placeholder.empty()  # æ¸…é™¤æç¤º

    #         # ğŸ” å…³é”®ï¼šè§¦å‘é‡è¿è¡Œï¼Œè®©å¤–éƒ¨ç«‹å³è¯»å–æ–°å€¼
    #         st.rerun()

    #     else:
    #         # âŒ æœªè¯†åˆ«åˆ°è¯­éŸ³
    #         status_placeholder.markdown("""
    #         <div style="
    #             background-color: #ffebee;
    #             border: 1px solid #f44336;
    #             border-radius: 4px;
    #             padding: 10px;
    #             margin: 10px 0;
    #             font-size: 14px;
    #         ">
    #             âŒ æ²’æœ‰è­˜åˆ¥åˆ°èªéŸ³ï¼Œè«‹é‡è©¦
    #         </div>
    #         """, unsafe_allow_html=True)

    #         time.sleep(1.5)
    #         status_placeholder.empty()

    # # è¿”å› Noneï¼ˆå¤–éƒ¨ä¸ä¾èµ–è¿”å›å€¼ï¼‰
    # return None
    language_mapping = {
        "yue_hk": "yue-HK",  # ç²¤è¯­ï¼ˆé¦™æ¸¯ï¼‰
        "zh": "zh-TW",       # ä¸­æ–‡ï¼ˆç¹ä½“ï¼‰
        "zh-cn": "zh-CN",    # ä¸­æ–‡ï¼ˆç®€ä½“ï¼‰
        "en": "en-US"        # è‹±è¯­
    }
    google_language = language_mapping.get(language, "yue-HK")

    # åˆå§‹åŒ– session_state
    if "is_recording" not in st.session_state:
        st.session_state["is_recording"] = False
    if "voice_transcribed_text" not in st.session_state:
        st.session_state["voice_transcribed_text"] = ""
    if "input_counter" not in st.session_state:
        st.session_state["input_counter"] = 0

    # ===== ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨ speech_to_text æ¸²æŸ“æŒ‰é’® =====
    text = speech_to_text(
        start_prompt="ğŸ¤ èªéŸ³è¼¸å…¥",
        stop_prompt="â¹ï¸ åœæ­¢éŒ„éŸ³",
        language=google_language,
        use_container_width=True,
        just_once=True,
        key="voice_recorder"
    )

    # åŒæ­¥ recording çŠ¶æ€ï¼ˆç”¨äº UI åé¦ˆï¼‰
    st.session_state["is_recording"] = bool(st.session_state.get("voice_recorder", False))



    # ===== ç¬¬å››æ­¥ï¼šçŠ¶æ€æç¤ºï¼ˆåœ¨æŒ‰é’®ä¸‹æ–¹ï¼‰=====
    status_placeholder = st.empty()

    if text is not None:
        st.session_state["is_recording"] = False
        recognized_text = text.strip()

        status_placeholder.empty()  # æ¸…é™¤æ—§æç¤º

        if recognized_text:
            # âœ… æˆåŠŸè¯†åˆ«
            st.session_state["voice_transcribed_text"] = recognized_text
            st.session_state["input_counter"] += 1

            status_placeholder.markdown(f"""
            <div style="
                background-color: #e8f5e8;
                border: 1px solid #4caf50;
                border-radius: 4px;
                padding: 10px;
                margin: 10px 0;  /* ä¸Šä¸‹ç•™ç™½ä¸€è‡´ */
                font-size: 14px;
            ">
                âœ… èªéŸ³è­˜åˆ¥å®Œæˆ: <strong>{recognized_text}</strong>
            </div>
            """, unsafe_allow_html=True)

            # ç­‰å¾…ç”¨æˆ·çœ‹åˆ°ç»“æœ
            time.sleep(1.2)
            status_placeholder.empty()  # æ¸…é™¤æç¤º

            # ğŸ” å…³é”®ï¼šè§¦å‘é‡è¿è¡Œï¼Œè®©å¤–éƒ¨ç«‹å³è¯»å–æ–°å€¼
            st.rerun()

        else:
            # âŒ æœªè¯†åˆ«åˆ°è¯­éŸ³
            status_placeholder.markdown("""
            <div style="
                background-color: #ffebee;
                border: 1px solid #f44336;
                border-radius: 4px;
                padding: 10px;
                margin: 10px 0;
                font-size: 14px;
            ">
                âŒ æ²’æœ‰è­˜åˆ¥åˆ°èªéŸ³ï¼Œè«‹é‡è©¦
            </div>
            """, unsafe_allow_html=True)

            time.sleep(1.5)
            status_placeholder.empty()

    return None